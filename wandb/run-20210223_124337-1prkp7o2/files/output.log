GPU detected
WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.
Loading data to memory
  0%|                                                   | 0/391 [00:00<?, ?it/s][0;31m---------------------------------------------------------------------------[0m
[0;31mResourceExhaustedError[0m                    Traceback (most recent call last)
[0;32m~/Desktop/IceCube_GNN/train_classification.py[0m in [0;36m<module>[0;34m[0m
[1;32m    280[0m [0;34m[0m[0m
[1;32m    281[0m [0;34m[0m[0m
[0;32m--> 282[0;31m [0mfig[0m[0;34m,[0m [0max[0m [0;34m=[0m [0mtest[0m[0;34m([0m[0mloader_test[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    283[0m [0mfig[0m[0;34m.[0m[0msavefig[0m[0;34m([0m[0;34mf"model_tests/{model_name}_test.pdf"[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/Desktop/IceCube_GNN/train_classification.py[0m in [0;36mtest[0;34m(loader)[0m
[1;32m    189[0m         [0minputs[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m[[0m[0;34m:[0m[0;34m,[0m [0;34m:[0m[0;36m3[0m[0;34m][0m [0;34m=[0m [0minputs[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m[[0m[0;34m:[0m[0;34m,[0m [0;34m:[0m[0;36m3[0m[0;34m][0m [0;34m/[0m [0;36m1000[0m[0;34m[0m[0;34m[0m[0m
[1;32m    190[0m         [0;31m# targets          = tf.squeeze(targets)[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 191[0;31m         [0mpredictions[0m[0;34m,[0m [0mtargets[0m[0;34m,[0m [0mout[0m [0;34m=[0m [0mtest_step[0m[0;34m([0m[0minputs[0m[0;34m,[0m [0mtargets[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    192[0m         [0mloss[0m           [0;34m+=[0m [0mout[0m[0;34m[0m[0;34m[0m[0m
[1;32m    193[0m [0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py[0m in [0;36m__call__[0;34m(self, *args, **kwds)[0m
[1;32m    826[0m     [0mtracing_count[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mexperimental_get_tracing_count[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    827[0m     [0;32mwith[0m [0mtrace[0m[0;34m.[0m[0mTrace[0m[0;34m([0m[0mself[0m[0;34m.[0m[0m_name[0m[0;34m)[0m [0;32mas[0m [0mtm[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 828[0;31m       [0mresult[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_call[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwds[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    829[0m       [0mcompiler[0m [0;34m=[0m [0;34m"xla"[0m [0;32mif[0m [0mself[0m[0;34m.[0m[0m_experimental_compile[0m [0;32melse[0m [0;34m"nonXla"[0m[0;34m[0m[0;34m[0m[0m
[1;32m    830[0m       [0mnew_tracing_count[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mexperimental_get_tracing_count[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py[0m in [0;36m_call[0;34m(self, *args, **kwds)[0m
[1;32m    892[0m               *args, **kwds)
[1;32m    893[0m       [0;31m# If we did not create any variables the trace we have is good enough.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 894[0;31m       return self._concrete_stateful_fn._call_flat(
[0m[1;32m    895[0m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access
[1;32m    896[0m [0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py[0m in [0;36m_call_flat[0;34m(self, args, captured_inputs, cancellation_manager)[0m
[1;32m   1916[0m         and executing_eagerly):
[1;32m   1917[0m       [0;31m# No tape is watching; skip to running the function.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1918[0;31m       return self._build_call_outputs(self._inference_function.call(
[0m[1;32m   1919[0m           ctx, args, cancellation_manager=cancellation_manager))
[1;32m   1920[0m     forward_backward = self._select_forward_and_backward_functions(

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py[0m in [0;36mcall[0;34m(self, ctx, args, cancellation_manager)[0m
[1;32m    553[0m       [0;32mwith[0m [0m_InterpolateFunctionError[0m[0;34m([0m[0mself[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    554[0m         [0;32mif[0m [0mcancellation_manager[0m [0;32mis[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 555[0;31m           outputs = execute.execute(
[0m[1;32m    556[0m               [0mstr[0m[0;34m([0m[0mself[0m[0;34m.[0m[0msignature[0m[0;34m.[0m[0mname[0m[0;34m)[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m    557[0m               [0mnum_outputs[0m[0;34m=[0m[0mself[0m[0;34m.[0m[0m_num_outputs[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py[0m in [0;36mquick_execute[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)[0m
[1;32m     57[0m   [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     58[0m     [0mctx[0m[0;34m.[0m[0mensure_initialized[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 59[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
[0m[1;32m     60[0m                                         inputs, attrs, num_outputs)
[1;32m     61[0m   [0;32mexcept[0m [0mcore[0m[0;34m.[0m[0m_NotOkStatusException[0m [0;32mas[0m [0me[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;31mResourceExhaustedError[0m: 2 root error(s) found.
  (0) Resource exhausted:  OOM when allocating tensor with shape[318537,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/StatefulPartitionedCall/StatefulPartitionedCall/ecc_conv/FGN_0/MatMul}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

  (1) Resource exhausted:  OOM when allocating tensor with shape[318537,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model/StatefulPartitionedCall/StatefulPartitionedCall/ecc_conv/FGN_0/MatMul}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[model/StatefulPartitionedCall/StatefulPartitionedCall/gcn_conv_3/Relu/_12]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored. [Op:__inference_test_step_3375]

Function call stack:
test_step -> test_step


[23;0t