GPU detected
Loading data to memory
  0%|                                                    | 0/79 [00:00<?, ?it/s]  1%|â–Œ                                           | 1/79 [00:11<14:33, 11.19s/it]Epoch 1 / 100; Avg_loss: 0.851355:   1%|         | 1/79 [00:11<14:33, 11.19s/it]Epoch 1 / 100; Avg_loss: 0.851355:   3%|â–        | 2/79 [00:12<10:26,  8.14s/it]Epoch 1 / 100; Avg_loss: 0.865839:   3%|â–        | 2/79 [00:12<10:26,  8.14s/it]Epoch 1 / 100; Avg_loss: 0.865839:   4%|â–Ž        | 3/79 [00:13<07:37,  6.01s/it]Epoch 1 / 100; Avg_loss: 0.853619:   4%|â–Ž        | 3/79 [00:13<07:37,  6.01s/it]Epoch 1 / 100; Avg_loss: 0.853619:   5%|â–        | 4/79 [00:14<05:39,  4.52s/it]Epoch 1 / 100; Avg_loss: 0.835289:   5%|â–        | 4/79 [00:14<05:39,  4.52s/it]Epoch 1 / 100; Avg_loss: 0.835289:   6%|â–Œ        | 5/79 [00:15<04:19,  3.50s/it]Epoch 1 / 100; Avg_loss: 0.828777:   6%|â–Œ        | 5/79 [00:15<04:19,  3.50s/it]Epoch 1 / 100; Avg_loss: 0.828777:   8%|â–‹        | 6/79 [00:16<03:22,  2.78s/it]Epoch 1 / 100; Avg_loss: 0.827426:   8%|â–‹        | 6/79 [00:16<03:22,  2.78s/it]Epoch 1 / 100; Avg_loss: 0.827426:   9%|â–Š        | 7/79 [00:17<02:43,  2.27s/it]Epoch 1 / 100; Avg_loss: 0.824542:   9%|â–Š        | 7/79 [00:17<02:43,  2.27s/it]Epoch 1 / 100; Avg_loss: 0.824542:  10%|â–‰        | 8/79 [00:18<02:15,  1.91s/it]Epoch 1 / 100; Avg_loss: 0.817632:  10%|â–‰        | 8/79 [00:18<02:15,  1.91s/it]Epoch 1 / 100; Avg_loss: 0.817632:  11%|â–ˆ        | 9/79 [00:19<01:55,  1.65s/it]Epoch 1 / 100; Avg_loss: 0.813884:  11%|â–ˆ        | 9/79 [00:19<01:55,  1.65s/it]Epoch 1 / 100; Avg_loss: 0.813884:  13%|â–ˆ       | 10/79 [00:20<01:42,  1.48s/it]Epoch 1 / 100; Avg_loss: 0.810412:  13%|â–ˆ       | 10/79 [00:20<01:42,  1.48s/it]Epoch 1 / 100; Avg_loss: 0.810412:  14%|â–ˆ       | 11/79 [00:21<01:32,  1.35s/it]Epoch 1 / 100; Avg_loss: 0.805023:  14%|â–ˆ       | 11/79 [00:21<01:32,  1.35s/it]Epoch 1 / 100; Avg_loss: 0.805023:  15%|â–ˆâ–      | 12/79 [00:22<01:24,  1.26s/it]Epoch 1 / 100; Avg_loss: 0.800306:  15%|â–ˆâ–      | 12/79 [00:22<01:24,  1.26s/it]Epoch 1 / 100; Avg_loss: 0.800306:  16%|â–ˆâ–Ž      | 13/79 [00:23<01:19,  1.20s/it]Epoch 1 / 100; Avg_loss: 0.794394:  16%|â–ˆâ–Ž      | 13/79 [00:23<01:19,  1.20s/it]Epoch 1 / 100; Avg_loss: 0.794394:  18%|â–ˆâ–      | 14/79 [00:25<01:15,  1.16s/it]Epoch 1 / 100; Avg_loss: 0.790415:  18%|â–ˆâ–      | 14/79 [00:25<01:15,  1.16s/it]Epoch 1 / 100; Avg_loss: 0.790415:  19%|â–ˆâ–Œ      | 15/79 [00:26<01:12,  1.14s/it]Epoch 1 / 100; Avg_loss: 0.787362:  19%|â–ˆâ–Œ      | 15/79 [00:26<01:12,  1.14s/it]Epoch 1 / 100; Avg_loss: 0.787362:  20%|â–ˆâ–Œ      | 16/79 [00:27<01:10,  1.12s/it]Epoch 1 / 100; Avg_loss: 0.783296:  20%|â–ˆâ–Œ      | 16/79 [00:27<01:10,  1.12s/it]Epoch 1 / 100; Avg_loss: 0.783296:  22%|â–ˆâ–‹      | 17/79 [00:28<01:08,  1.10s/it]Epoch 1 / 100; Avg_loss: 0.779340:  22%|â–ˆâ–‹      | 17/79 [00:28<01:08,  1.10s/it]Epoch 1 / 100; Avg_loss: 0.779340:  23%|â–ˆâ–Š      | 18/79 [00:29<01:06,  1.09s/it]Epoch 1 / 100; Avg_loss: 0.776881:  23%|â–ˆâ–Š      | 18/79 [00:29<01:06,  1.09s/it]Epoch 1 / 100; Avg_loss: 0.776881:  24%|â–ˆâ–‰      | 19/79 [00:30<01:04,  1.08s/it]Epoch 1 / 100; Avg_loss: 0.773001:  24%|â–ˆâ–‰      | 19/79 [00:30<01:04,  1.08s/it][0;31m---------------------------------------------------------------------------[0m
[0;31mResourceExhaustedError[0m                    Traceback (most recent call last)
[0;32m~/Desktop/IceCube_GNN/train_classification.py[0m in [0;36m<module>[0;34m[0m
[1;32m    223[0m     [0minputs[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m[[0m[0;34m:[0m[0;34m,[0m [0;36m3[0m[0;34m][0m  [0;34m=[0m [0minputs[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m[[0m[0;34m:[0m[0;34m,[0m [0;36m3[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[1;32m    224[0m     [0;31m# targets          = tf.squeeze(targets)[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 225[0;31m     [0mout[0m              [0;34m=[0m [0mtrain_step[0m[0;34m([0m[0minputs[0m[0;34m,[0m [0mtargets[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    226[0m     [0mloss[0m            [0;34m+=[0m [0mout[0m[0;34m[0m[0;34m[0m[0m
[1;32m    227[0m [0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py[0m in [0;36m__call__[0;34m(self, *args, **kwds)[0m
[1;32m    826[0m     [0mtracing_count[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mexperimental_get_tracing_count[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    827[0m     [0;32mwith[0m [0mtrace[0m[0;34m.[0m[0mTrace[0m[0;34m([0m[0mself[0m[0;34m.[0m[0m_name[0m[0;34m)[0m [0;32mas[0m [0mtm[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 828[0;31m       [0mresult[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_call[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwds[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    829[0m       [0mcompiler[0m [0;34m=[0m [0;34m"xla"[0m [0;32mif[0m [0mself[0m[0;34m.[0m[0m_experimental_compile[0m [0;32melse[0m [0;34m"nonXla"[0m[0;34m[0m[0;34m[0m[0m
[1;32m    830[0m       [0mnew_tracing_count[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mexperimental_get_tracing_count[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py[0m in [0;36m_call[0;34m(self, *args, **kwds)[0m
[1;32m    853[0m       [0;31m# In this case we have created variables on the first call, so we run the[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[1;32m    854[0m       [0;31m# defunned version which is guaranteed to never create variables.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 855[0;31m       [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_stateless_fn[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwds[0m[0;34m)[0m  [0;31m# pylint: disable=not-callable[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    856[0m     [0;32melif[0m [0mself[0m[0;34m.[0m[0m_stateful_fn[0m [0;32mis[0m [0;32mnot[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    857[0m       [0;31m# Release the lock early so that multiple threads can perform the call[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py[0m in [0;36m__call__[0;34m(self, *args, **kwargs)[0m
[1;32m   2940[0m       (graph_function,
[1;32m   2941[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)
[0;32m-> 2942[0;31m     return graph_function._call_flat(
[0m[1;32m   2943[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
[1;32m   2944[0m [0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py[0m in [0;36m_call_flat[0;34m(self, args, captured_inputs, cancellation_manager)[0m
[1;32m   1916[0m         and executing_eagerly):
[1;32m   1917[0m       [0;31m# No tape is watching; skip to running the function.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1918[0;31m       return self._build_call_outputs(self._inference_function.call(
[0m[1;32m   1919[0m           ctx, args, cancellation_manager=cancellation_manager))
[1;32m   1920[0m     forward_backward = self._select_forward_and_backward_functions(

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py[0m in [0;36mcall[0;34m(self, ctx, args, cancellation_manager)[0m
[1;32m    553[0m       [0;32mwith[0m [0m_InterpolateFunctionError[0m[0;34m([0m[0mself[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    554[0m         [0;32mif[0m [0mcancellation_manager[0m [0;32mis[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 555[0;31m           outputs = execute.execute(
[0m[1;32m    556[0m               [0mstr[0m[0;34m([0m[0mself[0m[0;34m.[0m[0msignature[0m[0;34m.[0m[0mname[0m[0;34m)[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m    557[0m               [0mnum_outputs[0m[0;34m=[0m[0mself[0m[0;34m.[0m[0m_num_outputs[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py[0m in [0;36mquick_execute[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)[0m
[1;32m     57[0m   [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     58[0m     [0mctx[0m[0;34m.[0m[0mensure_initialized[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 59[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
[0m[1;32m     60[0m                                         inputs, attrs, num_outputs)
[1;32m     61[0m   [0;32mexcept[0m [0mcore[0m[0;34m.[0m[0m_NotOkStatusException[0m [0;32mas[0m [0me[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;31mResourceExhaustedError[0m:  OOM when allocating tensor with shape[315675,5,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[node gradient_tape/model/ecc_conv/MatMul/MatMul_1 (defined at /home/johannbs/Desktop/IceCube_GNN/train_classification.py:138) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
 [Op:__inference_train_step_2618]

Errors may have originated from an input operation.
Input Source operations connected to node gradient_tape/model/ecc_conv/MatMul/MatMul_1:
 model/ecc_conv/strided_slice_3 (defined at /home/johannbs/anaconda3/lib/python3.8/site-packages/spektral/layers/convolutional/ecc_conv.py:186)

Function call stack:
train_step


[23;0t