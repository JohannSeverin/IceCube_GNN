GPU detected
Loading data to memory
  0%|                                                    | 0/79 [00:00<?, ?it/s]  1%|â–Œ                                           | 1/79 [00:05<06:46,  5.22s/it]Epoch 1 / 100; Avg_loss: 0.888557:   1%|         | 1/79 [00:05<06:46,  5.22s/it]Epoch 1 / 100; Avg_loss: 0.888557:   3%|â–        | 2/79 [00:06<05:03,  3.94s/it]Epoch 1 / 100; Avg_loss: 0.868074:   3%|â–        | 2/79 [00:06<05:03,  3.94s/it]Epoch 1 / 100; Avg_loss: 0.868074:   4%|â–Ž        | 3/79 [00:07<03:50,  3.03s/it]Epoch 1 / 100; Avg_loss: 0.860166:   4%|â–Ž        | 3/79 [00:07<03:50,  3.03s/it]Epoch 1 / 100; Avg_loss: 0.860166:   5%|â–        | 4/79 [00:08<03:00,  2.41s/it]Epoch 1 / 100; Avg_loss: 0.845930:   5%|â–        | 4/79 [00:08<03:00,  2.41s/it][0;31m---------------------------------------------------------------------------[0m
[0;31mResourceExhaustedError[0m                    Traceback (most recent call last)
[0;32m~/Desktop/IceCube_GNN/train_classification.py[0m in [0;36m<module>[0;34m[0m
[1;32m    223[0m     [0minputs[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m[[0m[0;34m:[0m[0;34m,[0m [0;36m3[0m[0;34m][0m  [0;34m=[0m [0minputs[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m[[0m[0;34m:[0m[0;34m,[0m [0;36m3[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[1;32m    224[0m     [0;31m# targets          = tf.squeeze(targets)[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 225[0;31m     [0mout[0m              [0;34m=[0m [0mtrain_step[0m[0;34m([0m[0minputs[0m[0;34m,[0m [0mtargets[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    226[0m     [0mloss[0m            [0;34m+=[0m [0mout[0m[0;34m[0m[0;34m[0m[0m
[1;32m    227[0m [0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py[0m in [0;36m__call__[0;34m(self, *args, **kwds)[0m
[1;32m    826[0m     [0mtracing_count[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mexperimental_get_tracing_count[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    827[0m     [0;32mwith[0m [0mtrace[0m[0;34m.[0m[0mTrace[0m[0;34m([0m[0mself[0m[0;34m.[0m[0m_name[0m[0;34m)[0m [0;32mas[0m [0mtm[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 828[0;31m       [0mresult[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_call[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwds[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    829[0m       [0mcompiler[0m [0;34m=[0m [0;34m"xla"[0m [0;32mif[0m [0mself[0m[0;34m.[0m[0m_experimental_compile[0m [0;32melse[0m [0;34m"nonXla"[0m[0;34m[0m[0;34m[0m[0m
[1;32m    830[0m       [0mnew_tracing_count[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mexperimental_get_tracing_count[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py[0m in [0;36m_call[0;34m(self, *args, **kwds)[0m
[1;32m    853[0m       [0;31m# In this case we have created variables on the first call, so we run the[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[1;32m    854[0m       [0;31m# defunned version which is guaranteed to never create variables.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 855[0;31m       [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_stateless_fn[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwds[0m[0;34m)[0m  [0;31m# pylint: disable=not-callable[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    856[0m     [0;32melif[0m [0mself[0m[0;34m.[0m[0m_stateful_fn[0m [0;32mis[0m [0;32mnot[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    857[0m       [0;31m# Release the lock early so that multiple threads can perform the call[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py[0m in [0;36m__call__[0;34m(self, *args, **kwargs)[0m
[1;32m   2940[0m       (graph_function,
[1;32m   2941[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)
[0;32m-> 2942[0;31m     return graph_function._call_flat(
[0m[1;32m   2943[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
[1;32m   2944[0m [0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py[0m in [0;36m_call_flat[0;34m(self, args, captured_inputs, cancellation_manager)[0m
[1;32m   1916[0m         and executing_eagerly):
[1;32m   1917[0m       [0;31m# No tape is watching; skip to running the function.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1918[0;31m       return self._build_call_outputs(self._inference_function.call(
[0m[1;32m   1919[0m           ctx, args, cancellation_manager=cancellation_manager))
[1;32m   1920[0m     forward_backward = self._select_forward_and_backward_functions(

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py[0m in [0;36mcall[0;34m(self, ctx, args, cancellation_manager)[0m
[1;32m    553[0m       [0;32mwith[0m [0m_InterpolateFunctionError[0m[0;34m([0m[0mself[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    554[0m         [0;32mif[0m [0mcancellation_manager[0m [0;32mis[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 555[0;31m           outputs = execute.execute(
[0m[1;32m    556[0m               [0mstr[0m[0;34m([0m[0mself[0m[0;34m.[0m[0msignature[0m[0;34m.[0m[0mname[0m[0;34m)[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m    557[0m               [0mnum_outputs[0m[0;34m=[0m[0mself[0m[0;34m.[0m[0m_num_outputs[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py[0m in [0;36mquick_execute[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)[0m
[1;32m     57[0m   [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     58[0m     [0mctx[0m[0;34m.[0m[0mensure_initialized[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 59[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
[0m[1;32m     60[0m                                         inputs, attrs, num_outputs)
[1;32m     61[0m   [0;32mexcept[0m [0mcore[0m[0;34m.[0m[0m_NotOkStatusException[0m [0;32mas[0m [0me[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;31mResourceExhaustedError[0m:  OOM when allocating tensor with shape[297677,5,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[node gradient_tape/model/ecc_conv/MatMul/MatMul_1 (defined at /home/johannbs/Desktop/IceCube_GNN/train_classification.py:138) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
 [Op:__inference_train_step_2618]

Errors may have originated from an input operation.
Input Source operations connected to node gradient_tape/model/ecc_conv/MatMul/MatMul_1:
 model/ecc_conv/strided_slice_3 (defined at /home/johannbs/anaconda3/lib/python3.8/site-packages/spektral/layers/convolutional/ecc_conv.py:186)

Function call stack:
train_step


[23;0t