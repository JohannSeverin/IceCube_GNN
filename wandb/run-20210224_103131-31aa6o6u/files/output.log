GPU detected
Loading data to memory
  0%|                                                   | 0/196 [00:00<?, ?it/s]WARNING:tensorflow:Gradients do not exist for variables ['model/dense_3/kernel:0', 'model/dense_3/bias:0', 'model/dense_6/kernel:0', 'model/dense_6/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['model/dense_3/kernel:0', 'model/dense_3/bias:0', 'model/dense_6/kernel:0', 'model/dense_6/bias:0'] when minimizing the loss.
  1%|â–                                          | 1/196 [00:06<20:06,  6.19s/it]Epoch 1 / 100; Avg_loss: 2.812336:   1%|        | 1/196 [00:06<20:06,  6.19s/it]Epoch 1 / 100; Avg_loss: 2.812336:   1%|        | 2/196 [00:07<15:18,  4.74s/it]Epoch 1 / 100; Avg_loss: 2.835576:   1%|        | 2/196 [00:07<15:18,  4.74s/it]Epoch 1 / 100; Avg_loss: 2.835576:   2%|        | 3/196 [00:08<11:55,  3.71s/it]Epoch 1 / 100; Avg_loss: 2.822814:   2%|        | 3/196 [00:08<11:55,  3.71s/it][0;31m---------------------------------------------------------------------------[0m
[0;31mInvalidArgumentError[0m                      Traceback (most recent call last)
[0;32m~/Desktop/IceCube_GNN/train_likelihood.py[0m in [0;36m<module>[0;34m[0m
[1;32m    229[0m     [0minputs[0m[0;34m,[0m [0mtargets[0m  [0;34m=[0m [0mbatch[0m[0;34m[0m[0;34m[0m[0m
[1;32m    230[0m     [0minputs[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m[[0m[0;34m:[0m[0;34m,[0m [0;34m:[0m[0;36m3[0m[0;34m][0m [0;34m=[0m [0minputs[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m[[0m[0;34m:[0m[0;34m,[0m [0;34m:[0m[0;36m3[0m[0;34m][0m [0;34m/[0m [0;36m1000[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 231[0;31m     [0mout[0m              [0;34m=[0m [0mtrain_step[0m[0;34m([0m[0minputs[0m[0;34m,[0m [0mtargets[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    232[0m     [0mloss[0m            [0;34m+=[0m [0mout[0m[0;34m[0m[0;34m[0m[0m
[1;32m    233[0m [0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py[0m in [0;36m__call__[0;34m(self, *args, **kwds)[0m
[1;32m    826[0m     [0mtracing_count[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mexperimental_get_tracing_count[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    827[0m     [0;32mwith[0m [0mtrace[0m[0;34m.[0m[0mTrace[0m[0;34m([0m[0mself[0m[0;34m.[0m[0m_name[0m[0;34m)[0m [0;32mas[0m [0mtm[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 828[0;31m       [0mresult[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_call[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwds[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    829[0m       [0mcompiler[0m [0;34m=[0m [0;34m"xla"[0m [0;32mif[0m [0mself[0m[0;34m.[0m[0m_experimental_compile[0m [0;32melse[0m [0;34m"nonXla"[0m[0;34m[0m[0;34m[0m[0m
[1;32m    830[0m       [0mnew_tracing_count[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mexperimental_get_tracing_count[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py[0m in [0;36m_call[0;34m(self, *args, **kwds)[0m
[1;32m    853[0m       [0;31m# In this case we have created variables on the first call, so we run the[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[1;32m    854[0m       [0;31m# defunned version which is guaranteed to never create variables.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 855[0;31m       [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_stateless_fn[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwds[0m[0;34m)[0m  [0;31m# pylint: disable=not-callable[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    856[0m     [0;32melif[0m [0mself[0m[0;34m.[0m[0m_stateful_fn[0m [0;32mis[0m [0;32mnot[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    857[0m       [0;31m# Release the lock early so that multiple threads can perform the call[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py[0m in [0;36m__call__[0;34m(self, *args, **kwargs)[0m
[1;32m   2940[0m       (graph_function,
[1;32m   2941[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)
[0;32m-> 2942[0;31m     return graph_function._call_flat(
[0m[1;32m   2943[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
[1;32m   2944[0m [0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py[0m in [0;36m_call_flat[0;34m(self, args, captured_inputs, cancellation_manager)[0m
[1;32m   1916[0m         and executing_eagerly):
[1;32m   1917[0m       [0;31m# No tape is watching; skip to running the function.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1918[0;31m       return self._build_call_outputs(self._inference_function.call(
[0m[1;32m   1919[0m           ctx, args, cancellation_manager=cancellation_manager))
[1;32m   1920[0m     forward_backward = self._select_forward_and_backward_functions(

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py[0m in [0;36mcall[0;34m(self, ctx, args, cancellation_manager)[0m
[1;32m    553[0m       [0;32mwith[0m [0m_InterpolateFunctionError[0m[0;34m([0m[0mself[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    554[0m         [0;32mif[0m [0mcancellation_manager[0m [0;32mis[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 555[0;31m           outputs = execute.execute(
[0m[1;32m    556[0m               [0mstr[0m[0;34m([0m[0mself[0m[0;34m.[0m[0msignature[0m[0;34m.[0m[0mname[0m[0;34m)[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m    557[0m               [0mnum_outputs[0m[0;34m=[0m[0mself[0m[0;34m.[0m[0m_num_outputs[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py[0m in [0;36mquick_execute[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)[0m
[1;32m     57[0m   [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     58[0m     [0mctx[0m[0;34m.[0m[0mensure_initialized[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 59[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
[0m[1;32m     60[0m                                         inputs, attrs, num_outputs)
[1;32m     61[0m   [0;32mexcept[0m [0mcore[0m[0;34m.[0m[0m_NotOkStatusException[0m [0;32mas[0m [0me[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;31mInvalidArgumentError[0m:  Input is not invertible.
	 [[node gradient_tape/MatrixInverse (defined at /home/johannbs/Desktop/IceCube_GNN/train_likelihood.py:155) ]] [Op:__inference_train_step_2691]

Errors may have originated from an input operation.
Input Source operations connected to node gradient_tape/MatrixInverse:
 diag (defined at /home/johannbs/Desktop/IceCube_GNN/loss_functions.py:101)

Function call stack:
train_step


[23;0t